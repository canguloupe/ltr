import pandas as pd
import numpy as np
from tqdm import tqdm
from sklearn.model_selection import GroupShuffleSplit
from xgboost import XGBRanker
from elasticsearch import Elasticsearch

# 1. Load Dataframes
# Assume df_examples and df_products are loaded as described in the user's input.

# df_examples = pd.read_csv('path/to/examples_data.csv')
# df_products = pd.read_csv('path/to/products_data.csv')

# Filter Data to only 'us' locale
us_examples = df_examples[df_examples['product_locale'] == 'us']
us_products = df_products[df_products['product_locale'] == 'us']

# Take a smaller sample of us_products
us_products_sample = us_products.sample(10000, random_state=42)

# Filter us_examples to only include product_ids in the sampled us_products
us_examples_sample = us_examples[us_examples['product_id'].isin(us_products_sample['product_id'])].copy()

# 2. Connect to Elasticsearch
# es = Elasticsearch(['http://localhost:9200'])  # Update with your Elasticsearch instance details

# 3. Create Elasticsearch Index for Product Data
index_name = "products"

if not es.indices.exists(index=index_name):
    es.indices.create(
        index=index_name,
        body={
            "mappings": {
                "properties": {
                    "product_title": {
                        "type": "text",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    },
                    "product_description": {
                        "type": "text",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    },
                    "product_bullet_point": {
                        "type": "text",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    },
                    "product_brand": {
                        "type": "text",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    },
                    "product_color": {
                        "type": "text",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    }
                }
            }
        }
    )

# 4. Index Products into Elasticsearch
for _, row in us_products_sample.iterrows():
    es.index(index=index_name, id=row['product_id'], body=row.to_dict())

# 5. Define Function to Get BM25 Score

def get_bm25_score(es, index_name, query, product_id):
    body = {
        "query": {
            "multi_match": {
                "query": query,
                "fields": [
                    "product_title^2",
                    "product_description",
                    "product_bullet_point"
                ]
            }
        }
    }
    res = es.search(index=index_name, body=body, _source=False, explain=True)
    score = 0
    for hit in res['hits']['hits']:
        if hit['_id'] == product_id:
            score = hit['_score']
            break
    return score

# 6. Add BM25 Score to df_examples
tqdm.pandas()
us_examples_sample.loc[:, 'bm25_score'] = us_examples_sample.progress_apply(
    lambda row: get_bm25_score(es, index_name, row['query'], row['product_id']), axis=1
)

# 7. Prepare Data for XGBoost
# Define features to train the model
features = ['bm25_score']
X = us_examples_sample[features]
y = us_examples_sample['esci_label'].map({'E': 3, 'S': 2, 'C': 1, 'I': 0})

# Group data by query_id for ranking
group_sizes = us_examples_sample.groupby('query_id').size().to_numpy()

# Split the data into training and validation sets while keeping the groups together
gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
train_idx, val_idx = next(gss.split(X, y, groups=us_examples_sample['query_id']))

X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
group_train = group_sizes[np.isin(us_examples_sample['query_id'].unique(), us_examples_sample['query_id'].iloc[train_idx].unique())]
group_val = group_sizes[np.isin(us_examples_sample['query_id'].unique(), us_examples_sample['query_id'].iloc[val_idx].unique())]

# 8. Train XGBoost Ranker Model for Learning to Rank
ranker = XGBRanker(
    objective="rank:ndcg",
    learning_rate=0.1,
    gamma=1.0,
    min_child_weight=1,
    max_depth=6
)

ranker.fit(
    X_train, y_train,
    group=group_train,
    eval_set=[(X_val, y_val)],
    eval_group=[group_val],
    verbose=True
)

# 9. Save Model for Later Use
ranker.save_model('ltr_xgboost_ranker_model.json')

# 10. Integrate with Elasticsearch
# Note: In production, you can use the trained model to generate scores for each query-product pair and re-rank the results in Elasticsearch.
